llm_providers:
  - name: dummy
    type: openai
    url: https://dummy.com
    models:
      - name: dummymodel
  - name: first-provider-name
    type: openai
    url: https://first-url:my-port/v1
    credentials_path: config/provider-keys/first-key.txt
    disable_model_check: true
  - name: second-provider-name
    type: openai
    url: https://second-url:my-port/v1
    credentials_path: config/provider-keys/second-key.txt
    disable_model_check: true
ols_config:
  conversation_cache:
    type: memory
    memory:
      max_entries: 1000
  authentication_config:
    module: "noop"
  default_provider: dummy
  default_model: dummymodel
  query_validation_method: llm
dev_config:
  enable_dev_ui: false
  disable_auth: false
  disable_tls: true
  enable_system_prompt_override: true
