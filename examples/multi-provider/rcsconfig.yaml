llm_providers:
  - name: dummy
    type: openai
    url: https://dummy.com
    models:
      - name: dummymodel
  - name: first-provider-name
    type: openai
    url: https://first-url:my-port/v1
    credentials_path: config/provider-keys/first-key.txt
    disable_model_check: true
  - name: second-provider-name
    type: openai
    url: https://second-url:my-port/v1
    credentials_path: config/provider-keys/second-key.txt
    disable_model_check: true
ols_config:
  conversation_cache:
    type: memory
    memory:
      max_entries: 1000
  authentication_config:
    module: "noop"
  default_provider: dummy
  default_model: dummymodel
  query_validation_method: llm
  user_data_collection:
    feedback_disabled: false
    feedback_storage: "/app-root/tmp/data/feedback"
dev_config:
  enable_dev_ui: false
  disable_auth: false
  disable_tls: true
  enable_system_prompt_override: true
user_data_collector_config:
  ingress_url: "https://example.ingress.com/upload"
  user_agent: "example-agent"